{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47225c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Om\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Om\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Om\\AppData\\Local\\Temp\\ipykernel_14352\\1198131346.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet18_model.load_state_dict(torch.load('resnet18_ct.pth', map_location=device))  # Load trained weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import joblib\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "# Set device for ResNet18 model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load Random Forest model and scaler\n",
    "rf_model = joblib.load('random_forest_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Load ResNet18 model architecture (as done in your notebook)\n",
    "from torchvision import models\n",
    "resnet18_model = models.resnet18(pretrained=False)  # No need to load pre-trained weights\n",
    "num_ftrs = resnet18_model.fc.in_features\n",
    "resnet18_model.fc = torch.nn.Linear(num_ftrs, 1)  # Modify final layer for binary classification\n",
    "resnet18_model.load_state_dict(torch.load('resnet18_ct.pth', map_location=device))  # Load trained weights\n",
    "resnet18_model.eval()\n",
    "resnet18_model.to(device)\n",
    "\n",
    "# Define transformations for CT scan image (same as used during training)\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Same normalization as training\n",
    "])\n",
    "\n",
    "# Function to get ResNet18 prediction (CT scan input)\n",
    "def resnet18_predict(ct_image_tensor, model):\n",
    "    with torch.no_grad():\n",
    "        ct_image_tensor = ct_image_tensor.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        output = model(ct_image_tensor)\n",
    "        prediction = torch.sigmoid(output).cpu().item()\n",
    "    return prediction\n",
    "\n",
    "# Function to get Random Forest prediction (urine analysis input)\n",
    "def rf_predict(urine_features, model, scaler):\n",
    "    urine_features_scaled = scaler.transform([urine_features])  # Scale the input features\n",
    "    prediction_proba = model.predict_proba(urine_features_scaled)[0][1]  # Probability of class 1 (stone present)\n",
    "    return prediction_proba\n",
    "\n",
    "# Gradio interface function to take inputs and return prediction\n",
    "def ensemble_predict(ct_image, gravity, ph, osmolarity, conductivity, urea, calcium):\n",
    "    # Convert the CT image to tensor\n",
    "    ct_image = Image.fromarray(ct_image)\n",
    "    ct_image_tensor = image_transforms(ct_image)\n",
    "    \n",
    "    # Prepare urine data for Random Forest\n",
    "    urine_data = [gravity, ph, osmolarity, conductivity, urea, calcium]\n",
    "    \n",
    "    # Get predictions from both models\n",
    "    resnet18_prediction = resnet18_predict(ct_image_tensor, resnet18_model)\n",
    "    rf_prediction = rf_predict(urine_data, rf_model, scaler)\n",
    "    \n",
    "    # Ensemble the predictions\n",
    "    resnet18_weight = 0.6  # Adjust based on performance\n",
    "    rf_weight = 0.4        # Adjust based on performance\n",
    "    ensemble_prediction = (resnet18_weight * resnet18_prediction) + (rf_weight * rf_prediction)\n",
    "    \n",
    "    # Convert ensemble prediction to class\n",
    "    ensemble_class = 1 if ensemble_prediction > 0.5 else 0\n",
    "    \n",
    "    # Output interpretation\n",
    "    return f\"Stone Present: {ensemble_class == 1} (Ensemble Score: {ensemble_prediction:.4f})\"\n",
    "\n",
    "# Gradio Interface\n",
    "interface = gr.Interface(\n",
    "    fn=ensemble_predict,\n",
    "    inputs=[\n",
    "        gr.Image(label=\"Upload CT Image\"),\n",
    "        gr.Number(label=\"Gravity\"),\n",
    "        gr.Number(label=\"pH\"),\n",
    "        gr.Number(label=\"Osmolarity\"),\n",
    "        gr.Number(label=\"Conductivity\"),\n",
    "        gr.Number(label=\"Urea Concentration\"),\n",
    "        gr.Number(label=\"Calcium Concentration\")\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"Kidney Stone Detection\",\n",
    "    description=\"Upload CT Image and enter urine details for kidney stone prediction\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d3b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
